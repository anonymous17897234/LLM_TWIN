{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"YOUR_API_KEY\")\n",
    "\n",
    "def get_survey_response(sex, age, questions_to_answer):\n",
    "    role = f\"\"\"\n",
    "        You are a Spanish netizen, answering this survey in early 2017. Answer all questions based on the provided demographic information(gender and age).\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "        **Data Provided:**\n",
    "\n",
    "        The survey respondent is {sex} and his(or her) age is {age}.\n",
    "\n",
    "        **Instructions:**\n",
    "\n",
    "        Consider general perspectives associated with your age and gender.\n",
    "        - Answer each question considering general perspectives associated with your age and gender. \n",
    "        - Format each response as follows: \"'Q<number>': <Answer> (reason for answer)\". Strictly adhere to the required response format without adding extra text or elaboration outside this structure.\n",
    "\n",
    "\n",
    "        **Survey Questions to Answer:**\n",
    "        {questions_to_answer}\n",
    "\n",
    "        **Example Response:**\n",
    "        [\n",
    "            'Q1': 7 (The respondent might show a very strong positive attitude towards this statement based on his age.),\n",
    "            'Q2': 1 (May indicate strong skepticism or disagreement with online ad reliability),\n",
    "            'Q3': 4 (Showing a neutral stance based in respondent's gender).\n",
    "        ]\n",
    "\n",
    "        Use a Likert scale from 1 to 7 (1 = Completely disagree to 7 = Completely agree) for each answer.\n",
    "        Respond in a structured format, outlining each step to form a well-supported evaluation.\n",
    "\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": role},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    result = response.choices[0].message.content\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def generate_answers(df, idx):\n",
    "    corresponding_ans = list(df.loc[idx])\n",
    "    answer_dic = {}\n",
    "    for i, ans in enumerate(corresponding_ans):\n",
    "        answer_dic[f'Q{i+1}'] = ans\n",
    "    answer_dic_str = \"\\n\".join([f\"{key}: {value}\" for key, value in answer_dic.items()])\n",
    "    return answer_dic_str"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "prior_df = pd.read_csv('../../../data/dv_total.csv', index_col=0)\n",
    "target_df = pd.read_csv('../../../data/idv_total.csv', index_col=0)\n",
    "\n",
    "idx_list = list(prior_df.index)\n",
    "if idx_list != list(target_df.index):\n",
    "    print(\"Error!\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "with open(f\"../../prior_questions.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    prior_questions = file.read()\n",
    "with open(f\"../../questions_to_answer.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    questions_to_answer = file.read()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "progress = 0\n",
    "answer_list = {}\n",
    "save_path = 'PATH_TO_SAVE_RESPONSES'\n",
    "\n",
    "for idx in idx_list:\n",
    "    progress+=1\n",
    "    if progress%50 == 0:\n",
    "        print(f\"progres {progress} done\")\n",
    "\n",
    "    sex = prior_df.loc[idx, 'Sex']\n",
    "    age = prior_df.loc[idx, 'Age']\n",
    "\n",
    "    gpt_answers_raw = get_survey_response(sex, age, questions_to_answer) ## responses generated by LLM\n",
    "    gpt_answers = re.findall(r\"[\\\"']Q\\d+[\\\"']:\\s*(\\d+)\", gpt_answers_raw)\n",
    "    gpt_answers = list(map(int, gpt_answers))\n",
    "    \n",
    "    human_answers_with_Q = generate_answers(target_df, idx) ## Original human respones\n",
    "    human_answers = re.findall(r': (\\d+)', str(human_answers_with_Q))\n",
    "    human_answers = list(map(int, human_answers))\n",
    "\n",
    "    answer_list[idx] = gpt_answers\n",
    "\n",
    "    if len(gpt_answers) == len(human_answers):\n",
    "        check = [1 if gpt_answers[i] == human_answers[i] else 0 for i in range(len(gpt_answers))]\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"raw_answer\": gpt_answers_raw,\n",
    "            \"gpt_answers\": gpt_answers,\n",
    "            \"human_answers\": human_answers,\n",
    "            \"check\": check\n",
    "        })\n",
    "        df.to_csv(f'{save_path}idx_{idx}_result.csv', index=False)\n",
    "    \n",
    "    else:\n",
    "        print(f\"The lengths of gpt answers and human answers for {idx} do not match.\")\n",
    "        df = pd.DataFrame({\n",
    "            \"raw_answer\": gpt_answers_raw,\n",
    "            \"human_answers\": human_answers,\n",
    "        })\n",
    "        df.to_csv(f'{save_path}idx_{idx}_result.csv', index=False)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "gpt_aoa = pd.DataFrame.from_dict(answer_list, orient=\"index\", columns=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"])\n",
    "gpt_aoa.to_csv(f'{save_path}llm_responses.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}