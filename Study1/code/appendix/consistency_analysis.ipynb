{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "distance_dict = {\n",
    "    1: -1, \n",
    "    2: -1, \n",
    "    3: -1, \n",
    "    4: 0, \n",
    "    5: 1, \n",
    "    6: 1, \n",
    "    7: 1\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "original_df = pd.read_csv('../../data/idv_total.csv', index_col=0)\n",
    "base_path = '../../data'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "results = []\n",
    "\n",
    "for folder in os.listdir(base_path):\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        llm_file = os.path.join(folder_path, 'llm_responses.csv')\n",
    "        llm_df = pd.read_csv(llm_file, index_col=0)\n",
    "        print(f\"==========Results of {folder}===========\\n\")\n",
    "\n",
    "        original_df_mapped = original_df.applymap(lambda x: distance_dict.get(x, None))\n",
    "        llm_df_mapped = llm_df.applymap(lambda x: distance_dict.get(x, None))\n",
    "        if list(original_df_mapped.index) != list(llm_df_mapped.index):\n",
    "            print(\"Error!\")\n",
    "\n",
    "        llm_df_mapped['Q1_original'] = original_df_mapped['aoa_1']\n",
    "        llm_df_mapped['Q2_original'] = original_df_mapped['aoa_2']\n",
    "        llm_df_mapped['Q3_original'] = original_df_mapped['aoa_3']\n",
    "        llm_df_mapped['Q4_original'] = original_df_mapped['aoa_4']\n",
    "\n",
    "        llm_df_mapped['Q1_check'] = np.where(llm_df_mapped['Q1_original'] == llm_df_mapped['Q1'], 1, 0)\n",
    "        llm_df_mapped['Q2_check'] = np.where(llm_df_mapped['Q2_original'] == llm_df_mapped['Q2'], 1, 0)\n",
    "        llm_df_mapped['Q3_check'] = np.where(llm_df_mapped['Q3_original'] == llm_df_mapped['Q3'], 1, 0)\n",
    "        llm_df_mapped['Q4_check'] = np.where(llm_df_mapped['Q4_original'] == llm_df_mapped['Q4'], 1, 0)\n",
    "\n",
    "        Q1_accuracy = llm_df_mapped['Q1_check'].mean() * 100\n",
    "        Q2_accuracy = llm_df_mapped['Q2_check'].mean() * 100\n",
    "        Q3_accuracy = llm_df_mapped['Q3_check'].mean() * 100\n",
    "        Q4_accuracy = llm_df_mapped['Q4_check'].mean() * 100\n",
    "\n",
    "        mean_accuracy = (Q1_accuracy + Q2_accuracy + Q3_accuracy + Q4_accuracy) / 4\n",
    "\n",
    "        print(f\"Q1 Accuracy: {Q1_accuracy:.2f}%\")\n",
    "        print(f\"Q2 Accuracy: {Q2_accuracy:.2f}%\")\n",
    "        print(f\"Q3 Accuracy: {Q3_accuracy:.2f}%\")\n",
    "        print(f\"Q4 Accuracy: {Q4_accuracy:.2f}%\")\n",
    "        print(f\"Mean Accuracy: {mean_accuracy:.2f}%\\n\")\n",
    "\n",
    "        results.append({\n",
    "            'Folder': folder,\n",
    "            'Q1_Accuracy': Q1_accuracy,\n",
    "            'Q2_Accuracy': Q2_accuracy,\n",
    "            'Q3_Accuracy': Q3_accuracy,\n",
    "            'Q4_Accuracy': Q4_accuracy,\n",
    "            'Mean_Accuracy': mean_accuracy\n",
    "        })"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "==========Results of baseline_prompting===========\n",
      "\n",
      "Q1 Accuracy: 53.01%\n",
      "Q2 Accuracy: 51.56%\n",
      "Q3 Accuracy: 68.37%\n",
      "Q4 Accuracy: 78.76%\n",
      "Mean Accuracy: 62.92%\n",
      "\n",
      "==========Results of omni_prompting===========\n",
      "\n",
      "Q1 Accuracy: 63.40%\n",
      "Q2 Accuracy: 69.76%\n",
      "Q3 Accuracy: 71.94%\n",
      "Q4 Accuracy: 80.41%\n",
      "Mean Accuracy: 71.38%\n",
      "\n",
      "==========Results of persona_driven_prompting===========\n",
      "\n",
      "Q1 Accuracy: 60.95%\n",
      "Q2 Accuracy: 67.11%\n",
      "Q3 Accuracy: 70.28%\n",
      "Q4 Accuracy: 79.35%\n",
      "Mean Accuracy: 69.42%\n",
      "\n",
      "==========Results of demo_prompting===========\n",
      "\n",
      "Q1 Accuracy: 40.37%\n",
      "Q2 Accuracy: 51.22%\n",
      "Q3 Accuracy: 67.97%\n",
      "Q4 Accuracy: 78.29%\n",
      "Mean Accuracy: 59.46%\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('../../analysis_result/appendix/consistency_analysis/result.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}