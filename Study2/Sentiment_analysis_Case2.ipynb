{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names for question items\n",
    "ori_responses = [\"SAT_1\", \"SAT_2\", \"SAT_3\", \"LOY_1\", \"LOY_2\", \"LOY_3\", \"TRUST_1\", \"TRUST_2\", \"TRUST_3\", \"TRUST_4\"]\n",
    "target_df = pd.read_excel('DataInBrief_Bankdata.xlsx')\n",
    "selected_columns_df = target_df[ori_responses]\n",
    "base_path = './Data_Case2' ## example path for given result data we provided\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_dict = {\n",
    "    1: -1, \n",
    "    2: -1, \n",
    "    3: -1, \n",
    "    4: 0, \n",
    "    5: 1, \n",
    "    6: 1, \n",
    "    7: 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Results of Baseline_prompting===========\n",
      "\n",
      "Q1 Accuracy: 82.52%\n",
      "Q2 Accuracy: 82.07%\n",
      "Q3 Accuracy: 75.26%\n",
      "Q4 Accuracy: 84.89%\n",
      "Q5 Accuracy: 44.15%\n",
      "Q6 Accuracy: 37.48%\n",
      "Q7 Accuracy: 47.41%\n",
      "Q8 Accuracy: 42.07%\n",
      "Q9 Accuracy: 50.52%\n",
      "Q10 Accuracy: 49.48%\n",
      "Mean Accuracy: 59.59%\n",
      "\n",
      "==========Results of Demo_prompting===========\n",
      "\n",
      "Q1 Accuracy: 80.00%\n",
      "Q2 Accuracy: 78.96%\n",
      "Q3 Accuracy: 55.11%\n",
      "Q4 Accuracy: 84.44%\n",
      "Q5 Accuracy: 33.04%\n",
      "Q6 Accuracy: 38.22%\n",
      "Q7 Accuracy: 41.48%\n",
      "Q8 Accuracy: 38.37%\n",
      "Q9 Accuracy: 37.04%\n",
      "Q10 Accuracy: 38.96%\n",
      "Mean Accuracy: 52.56%\n",
      "\n",
      "==========Results of Omni_prompting===========\n",
      "\n",
      "Q1 Accuracy: 86.37%\n",
      "Q2 Accuracy: 85.04%\n",
      "Q3 Accuracy: 85.04%\n",
      "Q4 Accuracy: 83.85%\n",
      "Q5 Accuracy: 62.22%\n",
      "Q6 Accuracy: 45.04%\n",
      "Q7 Accuracy: 70.67%\n",
      "Q8 Accuracy: 71.56%\n",
      "Q9 Accuracy: 66.81%\n",
      "Q10 Accuracy: 73.48%\n",
      "Mean Accuracy: 73.01%\n",
      "\n",
      "==========Results of Persona_Driven_prompting===========\n",
      "\n",
      "Q1 Accuracy: 84.74%\n",
      "Q2 Accuracy: 84.74%\n",
      "Q3 Accuracy: 79.26%\n",
      "Q4 Accuracy: 83.70%\n",
      "Q5 Accuracy: 58.81%\n",
      "Q6 Accuracy: 43.70%\n",
      "Q7 Accuracy: 67.26%\n",
      "Q8 Accuracy: 71.26%\n",
      "Q9 Accuracy: 64.89%\n",
      "Q10 Accuracy: 70.52%\n",
      "Mean Accuracy: 70.89%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for folder in os.listdir(base_path):\n",
    "    folder_path = os.path.join(base_path, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        llm_file = os.path.join(folder_path, 'llm_responses.csv')\n",
    "        llm_df = pd.read_csv(llm_file, index_col=0)\n",
    "        print(f\"==========Results of {folder}===========\\n\")\n",
    "\n",
    "        original_df_mapped = selected_columns_df.applymap(lambda x: distance_dict.get(x, None))\n",
    "        llm_df_mapped = llm_df.applymap(lambda x: distance_dict.get(x, None))\n",
    "        if list(original_df_mapped.index) != list(llm_df_mapped.index):\n",
    "            print(\"Error!\")\n",
    "        accuracies = []\n",
    "        for i in range(1, 11):\n",
    "            llm_df_mapped[f'Q{i}_original'] = original_df_mapped.iloc[:, i - 1]\n",
    "            llm_df_mapped[f'Q{i}_check'] = np.where(llm_df_mapped[f'Q{i}_original'] == llm_df_mapped[f'Q{i}'], 1, 0)\n",
    "            accuracy = llm_df_mapped[f'Q{i}_check'].mean() * 100\n",
    "            accuracies.append(accuracy)\n",
    "        mean_accuracy = sum(accuracies) / len(accuracies)\n",
    "        \n",
    "        print(f\"Q1 Accuracy: {accuracies[0]:.2f}%\")\n",
    "        print(f\"Q2 Accuracy: {accuracies[1]:.2f}%\")\n",
    "        print(f\"Q3 Accuracy: {accuracies[2]:.2f}%\")\n",
    "        print(f\"Q4 Accuracy: {accuracies[3]:.2f}%\")\n",
    "        print(f\"Q5 Accuracy: {accuracies[4]:.2f}%\")\n",
    "        print(f\"Q6 Accuracy: {accuracies[5]:.2f}%\")\n",
    "        print(f\"Q7 Accuracy: {accuracies[6]:.2f}%\")\n",
    "        print(f\"Q8 Accuracy: {accuracies[7]:.2f}%\")\n",
    "        print(f\"Q9 Accuracy: {accuracies[8]:.2f}%\")\n",
    "        print(f\"Q10 Accuracy: {accuracies[9]:.2f}%\")\n",
    "        print(f\"Mean Accuracy: {mean_accuracy:.2f}%\\n\")\n",
    "\n",
    "        results.append({\n",
    "            'Folder': folder,\n",
    "            'Q1_Accuracy': accuracies[0],\n",
    "            'Q2_Accuracy': accuracies[1],\n",
    "            'Q3_Accuracy': accuracies[2],\n",
    "            'Q4_Accuracy': accuracies[3],\n",
    "            'Q5_Accuracy': accuracies[4],\n",
    "            'Q6_Accuracy': accuracies[5],\n",
    "            'Q7_Accuracy': accuracies[6],\n",
    "            'Q8_Accuracy': accuracies[7],\n",
    "            'Q9_Accuracy': accuracies[8],\n",
    "            'Q10_Accuracy': accuracies[9],\n",
    "            'Mean_Accuracy': mean_accuracy\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './analysis_result/appendix/consistency_analysis_case2/'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('./analysis_result/appendix/consistency_analysis_case2/result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
